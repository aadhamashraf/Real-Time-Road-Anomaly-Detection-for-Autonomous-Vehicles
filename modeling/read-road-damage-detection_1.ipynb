{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7074449,"sourceType":"datasetVersion","datasetId":4006021}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **YOLO Version**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T09:08:27.162576Z","iopub.execute_input":"2025-03-30T09:08:27.162896Z","iopub.status.idle":"2025-03-30T09:08:27.166680Z","shell.execute_reply.started":"2025-03-30T09:08:27.162873Z","shell.execute_reply":"2025-03-30T09:08:27.165786Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"!nvidia-smi\n!pip install ultralytics\n!pip install opencv-python-headless\n!pip install -U ipywidgets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T09:08:27.169982Z","iopub.execute_input":"2025-03-30T09:08:27.170198Z","iopub.status.idle":"2025-03-30T09:08:38.726798Z","shell.execute_reply.started":"2025-03-30T09:08:27.170180Z","shell.execute_reply":"2025-03-30T09:08:38.725805Z"}},"outputs":[{"name":"stdout","text":"Sun Mar 30 09:08:27 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   76C    P0             33W /   70W |     313MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   43C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\nCollecting ultralytics\n  Downloading ultralytics-8.3.98-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.98-py3-none-any.whl (949 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m950.0/950.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.98 ultralytics-thop-2.0.14\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.2->opencv-python-headless) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python-headless) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.2->opencv-python-headless) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python-headless) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python-headless) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.2->opencv-python-headless) (2024.2.0)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.5)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.13)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (75.1.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"HOME = os.getcwd()\nprint(HOME)\nfrom IPython import display\ndisplay.clear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T09:08:38.728220Z","iopub.execute_input":"2025-03-30T09:08:38.728567Z","iopub.status.idle":"2025-03-30T09:08:38.734630Z","shell.execute_reply.started":"2025-03-30T09:08:38.728535Z","shell.execute_reply":"2025-03-30T09:08:38.733760Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import ultralytics\nultralytics.checks()\nfrom ultralytics import YOLO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T09:08:38.735994Z","iopub.execute_input":"2025-03-30T09:08:38.736212Z","iopub.status.idle":"2025-03-30T09:08:39.137999Z","shell.execute_reply.started":"2025-03-30T09:08:38.736192Z","shell.execute_reply":"2025-03-30T09:08:39.137395Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.98 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\nSetup complete âœ… (4 CPUs, 31.4 GB RAM, 6170.3/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"data_yaml_path = '/kaggle/input/radroad-anomaly-detection/images/data.yaml'\n\nmodel = YOLO('yolov8n.pt') \n\nmodel.train(data=data_yaml_path, epochs=25, imgsz=640, batch=8, save_period=5)\n\nmodel.train(data=data_yaml_path, epochs=15, imgsz=960, batch=8, save_period=5)\n\nmodel.train(data=data_yaml_path, epochs=10, imgsz=1280, batch=8, save_period=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T09:08:39.139128Z","iopub.execute_input":"2025-03-30T09:08:39.139389Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 84.8MB/s]","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.98 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/input/radroad-anomaly-detection/images/data.yaml, epochs=25, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 18.0MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=6\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \nModel summary: 129 layers, 3,012,018 parameters, 3,012,002 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 77.0MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/radroad-anomaly-detection/images/train/labels... 5843 images, 64 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5843/5843 [00:15<00:00, 368.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/radroad-anomaly-detection/images/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/radroad-anomaly-detection/images/valid/labels... 1288 images, 14 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1288/1288 [00:03<00:00, 347.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/radroad-anomaly-detection/images/valid is not writeable, cache not saved.\nPlotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 25 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/25      1.34G      1.775      2.127      1.317         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 731/731 [01:30<00:00,  8.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:11<00:00,  7.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1288       4559      0.696      0.371      0.394      0.196\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/25      1.41G      1.747      1.632      1.334         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 731/731 [01:26<00:00,  8.50it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:09<00:00,  8.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1288       4559      0.768      0.348      0.437      0.218\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/25      1.41G      1.731      1.512      1.325         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 731/731 [01:25<00:00,  8.56it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:09<00:00,  8.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1288       4559      0.481      0.463      0.451      0.229\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/25      1.41G      1.701      1.413      1.312         28        640:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 523/731 [01:01<00:25,  8.28it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# **No YOLO**","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T14:05:57.626736Z","iopub.execute_input":"2025-04-12T14:05:57.627018Z","iopub.status.idle":"2025-04-12T14:05:58.464232Z","shell.execute_reply.started":"2025-04-12T14:05:57.626997Z","shell.execute_reply":"2025-04-12T14:05:58.463382Z"}},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## **Transform YOLO Labels**\n\nUncomment this first","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\noriginal_base = '/kaggle/input/radroad-anomaly-detection/images'  \nnew_base = '/kaggle/working/binary_dataset'\n\nsplits = ['train', 'valid', 'test']\n\n# Make target directory structure\nfor split in splits:\n    for cls in ['normal', 'anomaly']:\n        os.makedirs(os.path.join(new_base, split, cls), exist_ok=True)\n\n# Label ID mapping\nanomaly_classes = [3, 5]\n\n# Loop through each split\nfor split in splits:\n    images_dir = os.path.join(original_base, split, 'images')\n    labels_dir = os.path.join(original_base, split, 'labels')\n    \n    for img_file in os.listdir(images_dir):\n        if not img_file.endswith(('.jpg', '.png', '.jpeg')):\n            continue\n        \n        # Get corresponding label file\n        img_path = os.path.join(images_dir, img_file)\n        label_filename = os.path.splitext(img_file)[0] + '.txt'\n        label_path = os.path.join(labels_dir, label_filename)\n\n        # Default to normal\n        target_class = 'normal'\n\n        # Check if label file exists and has content\n        if os.path.exists(label_path):\n            with open(label_path, 'r') as f:\n                lines = f.readlines()\n                # Check if any of the labels belong to anomaly classes (3 or 5)\n                for line in lines:\n                    class_id = int(line.split()[0])  # Get the class ID from the label line\n                    if class_id in anomaly_classes:\n                        target_class = 'anomaly'\n                        break\n        \n        # Copy image to new binary dataset\n        new_img_path = os.path.join(new_base, split, target_class, img_file)\n        shutil.copy(img_path, new_img_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T18:16:21.918938Z","iopub.execute_input":"2025-04-12T18:16:21.919257Z","iopub.status.idle":"2025-04-12T18:17:50.623940Z","shell.execute_reply.started":"2025-04-12T18:16:21.919232Z","shell.execute_reply":"2025-04-12T18:17:50.623021Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **Generalized Form for different models**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import EfficientNetB3, ResNet50, DenseNet121 , #VGG\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\n\nclass BinaryImageClassifier:\n    def __init__(self, model_name=\"ResNet50\", input_shape=(224, 224, 3), batch_size=32):\n        self.model_name = model_name\n        self.input_shape = input_shape\n        self.batch_size = batch_size\n        self.model = None\n        self.base_model = None\n        self.data_augmentation = self.get_data_augmentation()\n        self.Backbone, self.preprocess = self.get_backbone(model_name)\n\n    def load_datasets(self, train_dir, val_dir, test_dir):\n        train_ds = image_dataset_from_directory(\n            train_dir,\n            image_size=self.input_shape[:2],\n            batch_size=self.batch_size,\n            label_mode='binary'\n        )\n        val_ds = image_dataset_from_directory(\n            val_dir,\n            image_size=self.input_shape[:2],\n            batch_size=self.batch_size,\n            label_mode='binary'\n        )\n        test_ds = image_dataset_from_directory(\n            test_dir,\n            image_size=self.input_shape[:2],\n            batch_size=self.batch_size,\n            label_mode='binary'\n        )\n\n        AUTOTUNE = tf.data.AUTOTUNE\n        self.train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n        self.val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n        self.test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n\n    def get_data_augmentation(self):\n        return tf.keras.Sequential([\n            layers.RandomFlip(\"horizontal\"),\n            layers.RandomRotation(0.1),\n            layers.RandomZoom(0.1),\n            layers.RandomContrast(0.2),\n            layers.RandomBrightness(0.2),\n        ])\n\n    def get_backbone(self, name):\n        if name == \"EfficientNetB3\":\n            return EfficientNetB3, tf.keras.applications.efficientnet.preprocess_input\n        elif name == \"ResNet50\":\n            return ResNet50, tf.keras.applications.resnet.preprocess_input\n        elif name == \"DenseNet121\":\n            return DenseNet121, tf.keras.applications.densenet.preprocess_input\n        else:\n            raise ValueError(\"Invalid model name\")\n\n    def build_model(self):\n        self.base_model = self.Backbone(\n            include_top=False,\n            input_shape=self.input_shape,\n            weights='imagenet'\n        )\n        self.base_model.trainable = False\n\n        inputs = layers.Input(shape=self.input_shape)\n        x = self.data_augmentation(inputs)\n        x = self.preprocess(x)\n        x = self.base_model(x, training=False)\n        x = layers.GlobalAveragePooling2D()(x)\n        x = layers.Dropout(0.2)(x)\n        outputs = layers.Dense(1, activation='sigmoid')(x)\n\n        self.model = models.Model(inputs, outputs)\n\n    def compile_model(self, learning_rate=1e-3):\n        self.model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate),\n            loss='binary_crossentropy',\n            metrics=['accuracy']\n        )\n\n    def setup_callbacks(self):\n        checkpoint_cb = ModelCheckpoint(f\"best_{self.model_name}.keras\", save_best_only=True)\n        earlystop_cb = EarlyStopping(patience=5, restore_best_weights=True)\n        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n        return [checkpoint_cb, earlystop_cb, lr_scheduler]\n\n    def train(self, epochs=20):\n        callbacks = self.setup_callbacks()\n        history = self.model.fit(\n            self.train_ds,\n            validation_data=self.val_ds,\n            epochs=epochs,\n            callbacks=callbacks\n        )\n        return history\n\n    def fine_tune(self, fine_tune_at=None, epochs=20):\n        self.base_model.trainable = True\n        if fine_tune_at is None:\n            fine_tune_at = len(self.base_model.layers) // 2\n        for layer in self.base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n\n        self.compile_model(learning_rate=1e-5)\n        callbacks = self.setup_callbacks()\n        history = self.model.fit(\n            self.train_ds,\n            validation_data=self.val_ds,\n            epochs=epochs,\n            callbacks=callbacks\n        )\n        return history\n\n    def evaluate(self):\n        test_loss, test_acc = self.model.evaluate(self.test_ds)\n        print(f\"\\nâœ… Test Accuracy: {test_acc:.4f} | Loss: {test_loss:.4f}\")\n\n    def save_model(self):\n        self.model.save(f\"{self.model_name}_final_model.keras\")\n\n    def plot_history(self, histories, labels):\n        plt.figure(figsize=(14, 5))\n\n        # Accuracy Plot\n        plt.subplot(1, 2, 1)\n        for history, label in zip(histories, labels):\n            plt.plot(history.history['accuracy'], label=f'{label} Train')\n            plt.plot(history.history['val_accuracy'], label=f'{label} Val')\n        plt.title(f'{self.model_name} Accuracy')\n        plt.xlabel('Epoch')\n        plt.ylabel('Accuracy')\n        plt.legend()\n\n        # Loss Plot\n        plt.subplot(1, 2, 2)\n        for history, label in zip(histories, labels):\n            plt.plot(history.history['loss'], label=f'{label} Train')\n            plt.plot(history.history['val_loss'], label=f'{label} Val')\n        plt.title(f'{self.model_name} Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n\n        plt.tight_layout()\n        plt.savefig(f\"{self.model_name}_training_plot.png\")\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T18:17:50.625251Z","iopub.execute_input":"2025-04-12T18:17:50.625580Z","iopub.status.idle":"2025-04-12T18:18:03.700940Z","shell.execute_reply.started":"2025-04-12T18:17:50.625549Z","shell.execute_reply":"2025-04-12T18:18:03.700009Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"classifier = BinaryImageClassifier(model_name=\"DenseNet121\")\n\n# Load datasets\nclassifier.load_datasets(\n    train_dir='binary_dataset/train',\n    val_dir='binary_dataset/valid',\n    test_dir='binary_dataset/test'\n)\n\n# Build and compile model\nclassifier.build_model()\nclassifier.compile_model()\n\n# Train and fine-tune\nhistory1 = classifier.train(epochs=20)\nhistory2 = classifier.fine_tune(epochs=20)\n\n# Evaluate, save, and visualize\nclassifier.evaluate()\nclassifier.save_model()\nclassifier.plot_history([history1, history2], [\"Initial\", \"Fine-tune\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T18:18:03.702609Z","iopub.execute_input":"2025-04-12T18:18:03.703089Z"}},"outputs":[{"name":"stdout","text":"Found 5843 files belonging to 2 classes.\nFound 1288 files belonging to 2 classes.\nFound 1263 files belonging to 2 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m29084464/29084464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/20\n\u001b[1m183/183\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 214ms/step - accuracy: 0.5612 - loss: 0.7415 - val_accuracy: 0.6801 - val_loss: 0.5986 - learning_rate: 0.0010\nEpoch 2/20\n\u001b[1m183/183\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 188ms/step - accuracy: 0.6954 - loss: 0.5884 - val_accuracy: 0.7321 - val_loss: 0.5466 - learning_rate: 0.0010\nEpoch 3/20\n\u001b[1m183/183\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 217ms/step - accuracy: 0.7232 - loss: 0.5510 - val_accuracy: 0.7321 - val_loss: 0.5372 - learning_rate: 0.0010\nEpoch 4/20\n\u001b[1m183/183\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 202ms/step - accuracy: 0.7285 - loss: 0.5395 - val_accuracy: 0.7500 - val_loss: 0.5213 - learning_rate: 0.0010\nEpoch 5/20\n\u001b[1m183/183\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 195ms/step - accuracy: 0.7402 - loss: 0.5210 - val_accuracy: 0.7500 - val_loss: 0.5104 - learning_rate: 0.0010\nEpoch 6/20\n\u001b[1m183/183\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 193ms/step - accuracy: 0.7504 - loss: 0.5102 - val_accuracy: 0.7508 - val_loss: 0.5176 - learning_rate: 0.0010\nEpoch 7/20\n\u001b[1m183/183\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 197ms/step - accuracy: 0.7439 - loss: 0.5113 - val_accuracy: 0.7539 - val_loss: 0.5045 - learning_rate: 0.0010\nEpoch 8/20\n\u001b[1m183/183\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 196ms/step - accuracy: 0.7460 - loss: 0.5131 - val_accuracy: 0.7578 - val_loss: 0.4971 - learning_rate: 0.0010\nEpoch 9/20\n\u001b[1m183/183\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 192ms/step - accuracy: 0.7431 - loss: 0.5130 - val_accuracy: 0.7516 - val_loss: 0.5082 - learning_rate: 0.0010\nEpoch 10/20\n\u001b[1m 38/183\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m23s\u001b[0m 160ms/step - accuracy: 0.7423 - loss: 0.5236","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"classifier_2 = BinaryImageClassifier(model_name=\"ResNet50\")\n\n# Load datasets\nclassifier_2.load_datasets(\n    train_dir='binary_dataset/train',\n    val_dir='binary_dataset/valid',\n    test_dir='binary_dataset/test'\n)\n\n# Build and compile model\nclassifier_2.build_model()\nclassifier_2.compile_model()\n\n# Train and fine-tune\nhistory1_2 = classifier_2.train(epochs=20)\nhistory2_2 = classifier_2.fine_tune(epochs=20)\n\n# Evaluate, save, and visualize\nclassifier_2.evaluate()\nclassifier_2.save_model()\nclassifier_2.plot_history([history1_2, history2_2], [\"Initial\", \"Fine-tune\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classifier_3 = BinaryImageClassifier(model_name=\"EfficientNetB3\")\n\n# Load datasets\nclassifier_3.load_datasets(\n    train_dir='binary_dataset/train',\n    val_dir='binary_dataset/valid',\n    test_dir='binary_dataset/test'\n)\n\n# Build and compile model\nclassifier_3.build_model()\nclassifier_3.compile_model()\n\n# Train and fine-tune\nhistory1_3 = classifier_3.train(epochs=20)\nhistory2_3 = classifier_3.fine_tune(epochs=20)\n\n# Evaluate, save, and visualize\nclassifier_3.evaluate()\nclassifier_3.save_model()\nclassifier_3.plot_history([history1_3, history2_3], [\"Initial\", \"Fine-tune\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}