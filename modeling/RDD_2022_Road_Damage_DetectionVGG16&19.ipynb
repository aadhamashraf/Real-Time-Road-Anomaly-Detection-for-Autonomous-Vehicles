{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10827165,
          "sourceType": "datasetVersion",
          "datasetId": 6723075
        },
        {
          "sourceId": 11557599,
          "sourceType": "datasetVersion",
          "datasetId": 7246791
        },
        {
          "sourceId": 11558273,
          "sourceType": "datasetVersion",
          "datasetId": 7247171
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadhamashraf/Real-Time-Road-Anomaly-Detection-for-Autonomous-Vehicles/blob/main/modeling/RDD_2022_Road_Damage_DetectionVGG16%2619.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "MJ7uQrwuy92q"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "aliabdelmenam_rdd_2022_path = kagglehub.dataset_download('aliabdelmenam/rdd-2022')\n",
        "ziadalsawy_rdd_2022_path = kagglehub.dataset_download('ziadalsawy/rdd-2022')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "2Sc9tXcVy92r"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handling YOLO Formats and Generating Vectors**"
      ],
      "metadata": {
        "id": "EzoOP-OPy92s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How many Unique Class we Have ?**"
      ],
      "metadata": {
        "id": "94vXSwtvy92u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# def count_yolo_classes(label_dir):\n",
        "#     class_ids = set()\n",
        "\n",
        "#     for filename in os.listdir(label_dir):\n",
        "#         if filename.endswith(\".txt\"):\n",
        "#             filepath = os.path.join(label_dir, filename)\n",
        "#             with open(filepath, 'r') as f:\n",
        "#                 for line in f:\n",
        "#                     parts = line.strip().split()\n",
        "#                     if parts:  # avoid empty lines\n",
        "#                         class_id = int(parts[0])\n",
        "#                         class_ids.add(class_id)\n",
        "\n",
        "#     print(f\"Number of unique classes: {len(class_ids)}\")\n",
        "#     print(f\"Classes found: {sorted(class_ids)}\")\n",
        "\n",
        "# directory_path = \"/kaggle/input/rdd-2022/RDD_SPLIT/train/labels\"\n",
        "# count_yolo_classes(directory_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T07:10:40.427491Z",
          "iopub.execute_input": "2025-04-25T07:10:40.427764Z",
          "iopub.status.idle": "2025-04-25T07:13:16.64254Z",
          "shell.execute_reply.started": "2025-04-25T07:10:40.427743Z",
          "shell.execute_reply": "2025-04-25T07:13:16.641136Z"
        },
        "id": "iW6KCUTry92u",
        "outputId": "2f59d0a1-ae50-4ba1-f001-a01f79d6f751"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_31/2117168497.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdirectory_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/kaggle/input/rdd-2022/RDD_SPLIT/train/labels\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mcount_yolo_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_31/2117168497.py\u001b[0m in \u001b[0;36mcount_yolo_classes\u001b[0;34m(label_dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# avoid empty lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Frequency Resolving for each Label**"
      ],
      "metadata": {
        "id": "kIXtQiJny92v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from collections import Counter\n",
        "\n",
        "# labels_dir = '/kaggle/input/rdd-2022/RDD_SPLIT/train/labels'\n",
        "# all_classes = []\n",
        "\n",
        "# for label_file in os.listdir(labels_dir):\n",
        "#     if not label_file.endswith('.txt'):\n",
        "#         continue\n",
        "#     with open(os.path.join(labels_dir, label_file), 'r') as f:\n",
        "#         for line in f:\n",
        "#             class_id = int(line.strip().split()[0])\n",
        "#             all_classes.append(class_id)\n",
        "\n",
        "# print(Counter(all_classes))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-24T21:29:45.971824Z",
          "iopub.execute_input": "2025-04-24T21:29:45.972503Z",
          "iopub.status.idle": "2025-04-24T21:29:57.672922Z",
          "shell.execute_reply.started": "2025-04-24T21:29:45.972477Z",
          "shell.execute_reply": "2025-04-24T21:29:57.672179Z"
        },
        "id": "M2IXytQmy92w",
        "outputId": "3f546633-895b-435d-ffad-4bb446aba62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Counter({0: 18201, 1: 8386, 3: 7554, 2: 7527, 4: 4628})\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generating the CSV Files**"
      ],
      "metadata": {
        "id": "Pnrve3aJy92w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import shutil\n",
        "# import pandas as pd\n",
        "\n",
        "# # Define class mappings (human-readable damage labels)\n",
        "# class_id_to_name = {\n",
        "#     0: 'longitudinal_crack',\n",
        "#     1: 'transverse_crack',\n",
        "#     2: 'alligator_crack',\n",
        "#     3: 'pothole',\n",
        "#     4: 'other_damage'\n",
        "# }\n",
        "\n",
        "# class_names = list(class_id_to_name.values())\n",
        "# num_classes = len(class_names)\n",
        "\n",
        "# # Dataset paths\n",
        "# original_base = '/kaggle/input/rdd-2022/RDD_SPLIT'\n",
        "# splits = ['train', 'val', 'test']\n",
        "# new_base = '/kaggle/working/'\n",
        "\n",
        "# # Loop through the splits (train, val, test) to process CSVs\n",
        "# for split in splits:\n",
        "#     labels_dir = os.path.join(original_base, split, 'labels')\n",
        "#     data = []\n",
        "\n",
        "#     # Process each label file in the 'labels' directory\n",
        "#     for label_file in os.listdir(labels_dir):\n",
        "#         if not label_file.lower().endswith('.txt'):\n",
        "#             continue\n",
        "\n",
        "#         label_path = os.path.join(labels_dir, label_file)\n",
        "#         label_vector = [0] * num_classes\n",
        "\n",
        "#         with open(label_path, 'r') as f:\n",
        "#             for line in f:\n",
        "#                 class_id = int(line.strip().split()[0])\n",
        "#                 if class_id in class_id_to_name:\n",
        "#                     label_vector[class_id] = 1\n",
        "\n",
        "#         # Assuming you have a naming convention for image files (e.g., the label file name matches the image file name)\n",
        "#         img_file = label_file.replace('.txt', '.jpg')  # or .png, .jpeg based on your dataset format\n",
        "#         data.append([img_file] + label_vector)\n",
        "\n",
        "#     # Save the CSV file for the current split\n",
        "#     df = pd.DataFrame(data, columns=['filename'] + class_names)\n",
        "#     df.to_csv(os.path.join(new_base, f'{split}_labels.csv'), index=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-24T21:32:40.524902Z",
          "iopub.execute_input": "2025-04-24T21:32:40.525361Z",
          "iopub.status.idle": "2025-04-24T21:33:23.703127Z",
          "shell.execute_reply.started": "2025-04-24T21:32:40.525327Z",
          "shell.execute_reply": "2025-04-24T21:33:23.70256Z"
        },
        "id": "RjU1swUjy92x"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run From Here"
      ],
      "metadata": {
        "id": "rRXoyRQ850ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import kagglehub\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.applications import EfficientNetB3, VGG19, InceptionV3,VGG16\n",
        "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T07:13:16.642966Z",
          "iopub.status.idle": "2025-04-25T07:13:16.643246Z",
          "shell.execute_reply.started": "2025-04-25T07:13:16.643112Z",
          "shell.execute_reply": "2025-04-25T07:13:16.643125Z"
        },
        "id": "se-dZ96oy92y"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_2022_path = kagglehub.dataset_download('aliabdelmenam/rdd-2022')\n",
        "new_base = rdd_2022_path\n",
        "print(new_base)\n",
        "batch_size = 32\n",
        "target_size = (224, 224)\n",
        "class_names = ['longitudinal_crack', 'transverse_crack', 'alligator_crack', 'pothole', 'other_damage']\n",
        "num_classes = len(class_names)\n",
        "train_df = pd.read_csv(\"train_labels.csv\")\n",
        "val_df = pd.read_csv(\"val_labels.csv\")\n",
        "test_df = pd.read_csv(\"test_labels.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T07:13:23.903166Z",
          "iopub.execute_input": "2025-04-25T07:13:23.90352Z",
          "iopub.status.idle": "2025-04-25T07:13:23.958284Z",
          "shell.execute_reply.started": "2025-04-25T07:13:23.903495Z",
          "shell.execute_reply": "2025-04-25T07:13:23.957519Z"
        },
        "id": "LgU2BPLNy92y",
        "outputId": "581c360e-6926-4728-ed1b-f74451afcb48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# for root, dirs, files in os.walk(new_base):\n",
        "#     print(f\"Directory: {root}\")"
      ],
      "metadata": {
        "id": "P7mUz_nR3iCH",
        "outputId": "bcd73831-9697-42b0-b0ec-fe3a7567e84e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1\n",
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1/RDD_SPLIT\n",
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1/RDD_SPLIT/val\n",
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1/RDD_SPLIT/val/images\n",
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1/RDD_SPLIT/val/labels\n",
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1/RDD_SPLIT/test\n",
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1/RDD_SPLIT/test/images\n",
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1/RDD_SPLIT/test/labels\n",
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1/RDD_SPLIT/train\n",
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1/RDD_SPLIT/train/images\n",
            "Directory: /root/.cache/kagglehub/datasets/aliabdelmenam/rdd-2022/versions/1/RDD_SPLIT/train/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(df, directory, batch_size, target_size, class_names, shuffle=False):\n",
        "    def generator():\n",
        "        indices = df.index.tolist()\n",
        "        if shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "        for i in indices:\n",
        "            row = df.loc[i]\n",
        "            img_path = os.path.join(directory, row['filename'])\n",
        "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "            label = row[class_names].values.astype('float32')\n",
        "            yield img_array, label\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        generator,\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(*target_size, 3), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(num_classes,), dtype=tf.float32),\n",
        "        )\n",
        "    )\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(1024)\n",
        "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "2O5l5Yyqy92y"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(new_base, 'RDD_SPLIT/train/images')\n",
        "val_dir = os.path.join(new_base, 'RDD_SPLIT/val/images')\n",
        "test_dir = os.path.join(new_base, 'RDD_SPLIT/test/images')\n",
        "\n",
        "\n",
        "\n",
        "train_ds = create_dataset(train_df, train_dir, batch_size, target_size, class_names, shuffle=True)\n",
        "val_ds = create_dataset(val_df, val_dir, batch_size, target_size, class_names)\n",
        "test_ds = create_dataset(test_df, test_dir, batch_size, target_size, class_names)\n",
        "\n",
        "steps_per_epoch = len(train_df) // batch_size\n",
        "validation_steps = len(val_df) // batch_size\n",
        "test_steps = len(test_df) // batch_size\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.25),\n",
        "    layers.RandomZoom(0.5),\n",
        "    layers.RandomContrast(0.21),\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "id": "AkttZ8_cy92z"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modeling Phase"
      ],
      "metadata": {
        "id": "6i1C-uacy92z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG19"
      ],
      "metadata": {
        "id": "36XxD-Foy92z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_modelVGG19(input_shape=(224, 224, 3), num_classes=5):\n",
        "    base_model = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "    x = layers.Rescaling(1./255)(x)\n",
        "    x = base_model(x, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    return model,base_model"
      ],
      "metadata": {
        "id": "YAgyX7ap1KXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelVGG19, base_modelVGG19 = build_modelVGG19()\n",
        "modelVGG19.compile(optimizer='adam', loss=BinaryFocalCrossentropy(gamma=2.0), metrics=['binary_accuracy'])\n",
        "\n",
        "checkpoint_cb = callbacks.ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_binary_accuracy', mode='max')\n",
        "early_stop_cb = callbacks.EarlyStopping(patience=6, restore_best_weights=True)\n",
        "\n",
        "modelVGG19.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=20,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[checkpoint_cb, early_stop_cb]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "RQswrlzKy92z",
        "outputId": "e3fd9337-708a-4bd3-9660-76c97b17128c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 612ms/step - binary_accuracy: 0.7536 - loss: 0.1435 - val_binary_accuracy: 0.8007 - val_loss: 0.1183\n",
            "Epoch 2/20\n",
            "\u001b[1m  1/839\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31:36\u001b[0m 2s/step - binary_accuracy: 0.7714 - loss: 0.1328"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 92ms/step - binary_accuracy: 0.7714 - loss: 0.1328 - val_binary_accuracy: 0.8001 - val_loss: 0.1182\n",
            "Epoch 3/20\n",
            "\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 654ms/step - binary_accuracy: 0.7917 - loss: 0.1220 - val_binary_accuracy: 0.8027 - val_loss: 0.1168\n",
            "Epoch 4/20\n",
            "\u001b[1m  1/839\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 118ms/step - binary_accuracy: 0.8095 - loss: 0.1139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 92ms/step - binary_accuracy: 0.8095 - loss: 0.1139 - val_binary_accuracy: 0.8019 - val_loss: 0.1167\n",
            "Epoch 5/20\n",
            "\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 572ms/step - binary_accuracy: 0.7963 - loss: 0.1198 - val_binary_accuracy: 0.8084 - val_loss: 0.1172\n",
            "Epoch 6/20\n",
            "\u001b[1m  1/839\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 120ms/step - binary_accuracy: 0.8000 - loss: 0.1244"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 94ms/step - binary_accuracy: 0.8000 - loss: 0.1244 - val_binary_accuracy: 0.8075 - val_loss: 0.1169\n",
            "Epoch 7/20\n",
            "\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 597ms/step - binary_accuracy: 0.7948 - loss: 0.1196 - val_binary_accuracy: 0.8068 - val_loss: 0.1172\n",
            "Epoch 8/20\n",
            "\u001b[1m  1/839\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 121ms/step - binary_accuracy: 0.8000 - loss: 0.1166"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 161ms/step - binary_accuracy: 0.8000 - loss: 0.1166 - val_binary_accuracy: 0.8075 - val_loss: 0.1172\n",
            "Epoch 9/20\n",
            "\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 571ms/step - binary_accuracy: 0.7963 - loss: 0.1191 - val_binary_accuracy: 0.8064 - val_loss: 0.1151\n",
            "Epoch 10/20\n",
            "\u001b[1m  1/839\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 119ms/step - binary_accuracy: 0.8667 - loss: 0.0909"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 95ms/step - binary_accuracy: 0.8667 - loss: 0.0909 - val_binary_accuracy: 0.8063 - val_loss: 0.1151\n",
            "Epoch 11/20\n",
            "\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 608ms/step - binary_accuracy: 0.7950 - loss: 0.1195 - val_binary_accuracy: 0.8078 - val_loss: 0.1147\n",
            "Epoch 12/20\n",
            "\u001b[1m  1/839\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 121ms/step - binary_accuracy: 0.7905 - loss: 0.1194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 165ms/step - binary_accuracy: 0.7905 - loss: 0.1194 - val_binary_accuracy: 0.8079 - val_loss: 0.1148\n",
            "Epoch 13/20\n",
            "\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 642ms/step - binary_accuracy: 0.7966 - loss: 0.1188 - val_binary_accuracy: 0.8083 - val_loss: 0.1157\n",
            "Epoch 14/20\n",
            "\u001b[1m  1/839\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 136ms/step - binary_accuracy: 0.7714 - loss: 0.1245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 94ms/step - binary_accuracy: 0.7714 - loss: 0.1245 - val_binary_accuracy: 0.8084 - val_loss: 0.1157\n",
            "Epoch 15/20\n",
            "\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 575ms/step - binary_accuracy: 0.7957 - loss: 0.1187 - val_binary_accuracy: 0.8038 - val_loss: 0.1152\n",
            "Epoch 16/20\n",
            "\u001b[1m  1/839\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 133ms/step - binary_accuracy: 0.8095 - loss: 0.1178"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 99ms/step - binary_accuracy: 0.8095 - loss: 0.1178 - val_binary_accuracy: 0.8038 - val_loss: 0.1152\n",
            "Epoch 17/20\n",
            "\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 648ms/step - binary_accuracy: 0.7992 - loss: 0.1177 - val_binary_accuracy: 0.8088 - val_loss: 0.1148\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78cd189f3690>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "modelVGG19.load_weights('best_model.keras')\n",
        "test_loss, test_acc = modelVGG19.evaluate(test_ds.take(test_steps))\n",
        "print(f\"Test Accuracy: {test_acc:.4f} | Loss: {test_loss:.4f}\")\n",
        "\n",
        "y_true = test_df[class_names].values\n",
        "y_pred_probs = modelVGG19.predict(test_ds.take(test_steps))\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true[:len(y_pred)], y_pred, target_names=class_names))\n",
        "print(\"Macro F1 Score:\", f1_score(y_true[:len(y_pred)], y_pred, average='macro'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T06:22:03.538518Z",
          "iopub.execute_input": "2025-04-25T06:22:03.538835Z"
        },
        "id": "rezAotLCy920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508eee81-e2e8-4792-e628-4885139e1de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 511ms/step - binary_accuracy: 0.8096 - loss: 0.1138\n",
            "Test Accuracy: 0.8094 | Loss: 0.1137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 488ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "longitudinal_crack       0.67      0.35      0.46      2066\n",
            "  transverse_crack       0.40      0.01      0.01      1109\n",
            "   alligator_crack       0.63      0.03      0.06      1209\n",
            "           pothole       0.63      0.38      0.47      1094\n",
            "      other_damage       0.00      0.00      0.00       526\n",
            "\n",
            "         micro avg       0.65      0.20      0.30      6004\n",
            "         macro avg       0.47      0.15      0.20      6004\n",
            "      weighted avg       0.54      0.20      0.26      6004\n",
            "       samples avg       0.20      0.15      0.16      6004\n",
            "\n",
            "Macro F1 Score: 0.202129722249106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine tuning"
      ],
      "metadata": {
        "id": "A_7ffGAu44qT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_modelVGG19.layers[-5:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "modelVGG19.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss = BinaryFocalCrossentropy(gamma=2.0), metrics=['binary_accuracy'])\n",
        "\n",
        "modelVGG19.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs=20,\n",
        "    steps_per_epoch = steps_per_epoch,\n",
        "    validation_steps = validation_steps,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")"
      ],
      "metadata": {
        "id": "CvaNXmq9asbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelVGG19.load_weights('best_model.keras')\n",
        "test_loss, test_acc = modelVGG19.evaluate(test_ds.take(test_steps))\n",
        "print(f\"Test Accuracy: {test_acc:.4f} | Loss: {test_loss:.4f}\")\n",
        "\n",
        "y_true = test_df[class_names].values\n",
        "y_pred_probs = modelVGG19.predict(test_ds.take(test_steps))\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true[:len(y_pred)], y_pred, target_names=class_names))\n",
        "print(\"Macro F1 Score:\", f1_score(y_true[:len(y_pred)], y_pred, average='macro'))"
      ],
      "metadata": {
        "id": "lR4WHaRz4jMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16\n"
      ],
      "metadata": {
        "id": "L-J9aRaa4XMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_modelVGG16(input_shape=(224, 224, 3), num_classes=5):\n",
        "    base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "    x = layers.Rescaling(1./255)(x)\n",
        "    x = base_model(x, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.35)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    return model,base_model"
      ],
      "metadata": {
        "id": "O665b2Cq3kF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelVGG16, base_modelVGG16 = build_modelVGG16()\n",
        "modelVGG16.compile(optimizer='adam', loss=BinaryFocalCrossentropy(gamma=2.5), metrics=['binary_accuracy'])\n",
        "\n",
        "checkpoint_cb = callbacks.ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_binary_accuracy', mode='max')\n",
        "early_stop_cb = callbacks.EarlyStopping(patience=6, restore_best_weights=True)\n",
        "\n",
        "modelVGG16.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=20,\n",
        "    # steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[checkpoint_cb, early_stop_cb]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "g4olVYaY3ukm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f08ca2-1515-4772-9ff4-b73b9474e8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "    840/Unknown \u001b[1m423s\u001b[0m 483ms/step - binary_accuracy: 0.7484 - loss: 0.1046"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 589ms/step - binary_accuracy: 0.7485 - loss: 0.1046 - val_binary_accuracy: 0.7973 - val_loss: 0.0841\n",
            "Epoch 2/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - binary_accuracy: 0.7951 - loss: 0.0855"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 576ms/step - binary_accuracy: 0.7951 - loss: 0.0855 - val_binary_accuracy: 0.8060 - val_loss: 0.0827\n",
            "Epoch 3/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - binary_accuracy: 0.7973 - loss: 0.0845"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 569ms/step - binary_accuracy: 0.7973 - loss: 0.0845 - val_binary_accuracy: 0.8086 - val_loss: 0.0822\n",
            "Epoch 4/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - binary_accuracy: 0.7989 - loss: 0.0841"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 562ms/step - binary_accuracy: 0.7989 - loss: 0.0841 - val_binary_accuracy: 0.8059 - val_loss: 0.0809\n",
            "Epoch 5/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - binary_accuracy: 0.7995 - loss: 0.0838"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 570ms/step - binary_accuracy: 0.7995 - loss: 0.0838 - val_binary_accuracy: 0.8036 - val_loss: 0.0809\n",
            "Epoch 6/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - binary_accuracy: 0.7971 - loss: 0.0839"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 561ms/step - binary_accuracy: 0.7971 - loss: 0.0839 - val_binary_accuracy: 0.8005 - val_loss: 0.0811\n",
            "Epoch 7/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - binary_accuracy: 0.7982 - loss: 0.0836"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 556ms/step - binary_accuracy: 0.7982 - loss: 0.0836 - val_binary_accuracy: 0.8080 - val_loss: 0.0814\n",
            "Epoch 8/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - binary_accuracy: 0.7994 - loss: 0.0836"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 559ms/step - binary_accuracy: 0.7994 - loss: 0.0836 - val_binary_accuracy: 0.8059 - val_loss: 0.0817\n",
            "Epoch 9/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - binary_accuracy: 0.7969 - loss: 0.0838"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 559ms/step - binary_accuracy: 0.7969 - loss: 0.0838 - val_binary_accuracy: 0.8055 - val_loss: 0.0816\n",
            "Epoch 10/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - binary_accuracy: 0.7987 - loss: 0.0835"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 558ms/step - binary_accuracy: 0.7987 - loss: 0.0835 - val_binary_accuracy: 0.8061 - val_loss: 0.0805\n",
            "Epoch 11/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - binary_accuracy: 0.7983 - loss: 0.0835"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 562ms/step - binary_accuracy: 0.7983 - loss: 0.0835 - val_binary_accuracy: 0.8090 - val_loss: 0.0807\n",
            "Epoch 12/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - binary_accuracy: 0.8020 - loss: 0.0831"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 561ms/step - binary_accuracy: 0.8020 - loss: 0.0831 - val_binary_accuracy: 0.7979 - val_loss: 0.0812\n",
            "Epoch 13/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - binary_accuracy: 0.7995 - loss: 0.0832"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 565ms/step - binary_accuracy: 0.7995 - loss: 0.0832 - val_binary_accuracy: 0.8075 - val_loss: 0.0811\n",
            "Epoch 14/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - binary_accuracy: 0.7983 - loss: 0.0835"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 560ms/step - binary_accuracy: 0.7983 - loss: 0.0835 - val_binary_accuracy: 0.8111 - val_loss: 0.0810\n",
            "Epoch 15/20\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - binary_accuracy: 0.7974 - loss: 0.0838"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 563ms/step - binary_accuracy: 0.7974 - loss: 0.0838 - val_binary_accuracy: 0.8103 - val_loss: 0.0816\n",
            "Epoch 16/20\n",
            "\u001b[1m145/840\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:21\u001b[0m 462ms/step - binary_accuracy: 0.7978 - loss: 0.0841"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelVGG16.load_weights('best_model.keras')\n",
        "test_loss, test_acc = modelVGG16.evaluate(test_ds.take(test_steps))\n",
        "print(f\"Test Accuracy: {test_acc:.4f} | Loss: {test_loss:.4f}\")\n",
        "\n",
        "y_true = test_df[class_names].values\n",
        "y_pred_probs = modelVGG16.predict(test_ds.take(test_steps))\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true[:len(y_pred)], y_pred, target_names=class_names))\n",
        "print(\"Macro F1 Score:\", f1_score(y_true[:len(y_pred)], y_pred, average='macro'))"
      ],
      "metadata": {
        "id": "BUddAIyU3wqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine tuning"
      ],
      "metadata": {
        "id": "9Kx30pmZ5nlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_modelVGG16.layers[-5:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "modelVGG16.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss = BinaryFocalCrossentropy(gamma=2.0), metrics=['binary_accuracy'])\n",
        "\n",
        "modelVGG16.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs=10,\n",
        "    steps_per_epoch = steps_per_epoch,\n",
        "    validation_steps = validation_steps,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")"
      ],
      "metadata": {
        "id": "SeO_rXLLau3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelVGG16.load_weights('best_model.keras')\n",
        "test_loss, test_acc = modelVGG16.evaluate(test_ds.take(test_steps))\n",
        "print(f\"Test Accuracy: {test_acc:.4f} | Loss: {test_loss:.4f}\")\n",
        "\n",
        "y_true = test_df[class_names].values\n",
        "y_pred_probs = modelVGG16.predict(test_ds.take(test_steps))\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true[:len(y_pred)], y_pred, target_names=class_names))\n",
        "print(\"Macro F1 Score:\", f1_score(y_true[:len(y_pred)], y_pred, average='macro'))"
      ],
      "metadata": {
        "id": "pUknqek737gi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}