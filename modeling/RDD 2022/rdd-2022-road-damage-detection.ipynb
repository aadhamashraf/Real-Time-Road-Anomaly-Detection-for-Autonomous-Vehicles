{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10827165,"sourceType":"datasetVersion","datasetId":6723075},{"sourceId":11557599,"sourceType":"datasetVersion","datasetId":7246791}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Handling YOLO Formats and Generating Vectors**","metadata":{}},{"cell_type":"markdown","source":"## **How many Unique Class we Have ?**","metadata":{}},{"cell_type":"code","source":"# import os\n\n# def count_yolo_classes(label_dir):\n#     class_ids = set()\n    \n#     for filename in os.listdir(label_dir):\n#         if filename.endswith(\".txt\"):\n#             filepath = os.path.join(label_dir, filename)\n#             with open(filepath, 'r') as f:\n#                 for line in f:\n#                     parts = line.strip().split()\n#                     if parts:  # avoid empty lines\n#                         class_id = int(parts[0])\n#                         class_ids.add(class_id)\n    \n#     print(f\"Number of unique classes: {len(class_ids)}\")\n#     print(f\"Classes found: {sorted(class_ids)}\")\n\n# directory_path = \"/kaggle/input/rdd-2022/RDD_SPLIT/train/labels\"\n# count_yolo_classes(directory_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T21:25:43.722893Z","iopub.execute_input":"2025-04-24T21:25:43.723111Z","iopub.status.idle":"2025-04-24T21:26:45.814185Z","shell.execute_reply.started":"2025-04-24T21:25:43.723092Z","shell.execute_reply":"2025-04-24T21:26:45.813538Z"}},"outputs":[{"name":"stdout","text":"Number of unique classes: 5\nClasses found: [0, 1, 2, 3, 4]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## **Frequency Resolving for each Label**","metadata":{}},{"cell_type":"code","source":"# import os\n# from collections import Counter\n\n# labels_dir = '/kaggle/input/rdd-2022/RDD_SPLIT/train/labels'\n# all_classes = []\n\n# for label_file in os.listdir(labels_dir):\n#     if not label_file.endswith('.txt'):\n#         continue\n#     with open(os.path.join(labels_dir, label_file), 'r') as f:\n#         for line in f:\n#             class_id = int(line.strip().split()[0])\n#             all_classes.append(class_id)\n\n# print(Counter(all_classes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T21:29:45.971824Z","iopub.execute_input":"2025-04-24T21:29:45.972503Z","iopub.status.idle":"2025-04-24T21:29:57.672922Z","shell.execute_reply.started":"2025-04-24T21:29:45.972477Z","shell.execute_reply":"2025-04-24T21:29:57.672179Z"}},"outputs":[{"name":"stdout","text":"Counter({0: 18201, 1: 8386, 3: 7554, 2: 7527, 4: 4628})\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## **Generating the CSV Files**","metadata":{}},{"cell_type":"code","source":"# import os\n# import shutil\n# import pandas as pd\n\n# # Define class mappings (human-readable damage labels)\n# class_id_to_name = {\n#     0: 'longitudinal_crack',\n#     1: 'transverse_crack',\n#     2: 'alligator_crack',\n#     3: 'pothole',\n#     4: 'other_damage'\n# }\n\n# class_names = list(class_id_to_name.values())\n# num_classes = len(class_names)\n\n# # Dataset paths\n# original_base = '/kaggle/input/rdd-2022/RDD_SPLIT'\n# splits = ['train', 'val', 'test']\n# new_base = '/kaggle/working/'\n\n# # Loop through the splits (train, val, test) to process CSVs\n# for split in splits:\n#     labels_dir = os.path.join(original_base, split, 'labels')\n#     data = []\n\n#     # Process each label file in the 'labels' directory\n#     for label_file in os.listdir(labels_dir):\n#         if not label_file.lower().endswith('.txt'):\n#             continue\n\n#         label_path = os.path.join(labels_dir, label_file)\n#         label_vector = [0] * num_classes\n\n#         with open(label_path, 'r') as f:\n#             for line in f:\n#                 class_id = int(line.strip().split()[0])\n#                 if class_id in class_id_to_name:\n#                     label_vector[class_id] = 1\n\n#         # Assuming you have a naming convention for image files (e.g., the label file name matches the image file name)\n#         img_file = label_file.replace('.txt', '.jpg')  # or .png, .jpeg based on your dataset format\n#         data.append([img_file] + label_vector)\n\n#     # Save the CSV file for the current split\n#     df = pd.DataFrame(data, columns=['filename'] + class_names)\n#     df.to_csv(os.path.join(new_base, f'{split}_labels.csv'), index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T21:32:40.524902Z","iopub.execute_input":"2025-04-24T21:32:40.525361Z","iopub.status.idle":"2025-04-24T21:33:23.703127Z","shell.execute_reply.started":"2025-04-24T21:32:40.525327Z","shell.execute_reply":"2025-04-24T21:33:23.702560Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.losses import BinaryFocalCrossentropy\nfrom sklearn.metrics import classification_report, f1_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_base = '/kaggle/input/rdd-2022/RDD_SPLIT'\nbatch_size = 32\ntarget_size = (224, 224)\n\nclass_names = ['longitudinal_crack', 'transverse_crack', 'alligator_crack', 'pothole', 'other_damage']\nnum_classes = len(class_names)\n\ntrain_df = pd.read_csv(\"/kaggle/input/rdd-2022-encoded-labels/train_labels.csv\")\nval_df = pd.read_csv(\"/kaggle/input/rdd-2022-encoded-labels/val_labels.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/rdd-2022-encoded-labels/test_labels.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_dataset(df, directory, batch_size, target_size, class_names, shuffle=False):\n    def generator():\n        indices = df.index.tolist()\n        if shuffle:\n            np.random.shuffle(indices)\n        for i in indices:\n            row = df.loc[i]\n            img_path = os.path.join(directory, row['filename'])\n            img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n            img_array = tf.keras.preprocessing.image.img_to_array(img)\n            label = row[class_names].values.astype('float32')\n            yield img_array, label\n\n    dataset = tf.data.Dataset.from_generator(\n        generator,\n        output_signature=(\n            tf.TensorSpec(shape=(*target_size, 3), dtype=tf.float32),\n            tf.TensorSpec(shape=(num_classes,), dtype=tf.float32),\n        )\n    )\n    if shuffle:\n        dataset = dataset.shuffle(1024)\n    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = os.path.join(new_base, 'train/images')\nval_dir = os.path.join(new_base, 'val/images')\ntest_dir = os.path.join(new_base, 'test/images')\n\ntrain_ds = create_dataset(train_df, train_dir, batch_size, target_size, class_names, shuffle=True)\nval_ds = create_dataset(val_df, val_dir, batch_size, target_size, class_names)\ntest_ds = create_dataset(test_df, test_dir, batch_size, target_size, class_names)\n\nsteps_per_epoch = len(train_df) // batch_size\nvalidation_steps = len(val_df) // batch_size\ntest_steps = len(test_df) // batch_size\n\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n    layers.RandomContrast(0.1),\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Modeling Phase**","metadata":{}},{"cell_type":"markdown","source":"## **EfficientNetB3**","metadata":{}},{"cell_type":"code","source":"model, base_model = build_model()\nmodel.compile(optimizer='adam', loss=BinaryFocalCrossentropy(gamma=2.0), metrics=['binary_accuracy'])\n\ncheckpoint_cb = callbacks.ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_binary_accuracy', mode='max')\nearly_stop_cb = callbacks.EarlyStopping(patience=6, restore_best_weights=True)\n\nmodel.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=10,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=[checkpoint_cb, early_stop_cb]\n)\n\nfor layer in base_model.layers[-30:]:\n    layer.trainable = True\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss=BinaryFocalCrossentropy(gamma=2.0), metrics=['binary_accuracy'])\n\nmodel.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=10,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=[checkpoint_cb]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_weights('best_model.keras')\ntest_loss, test_acc = model.evaluate(test_ds.take(test_steps))\nprint(f\"Test Accuracy: {test_acc:.4f} | Loss: {test_loss:.4f}\")\n\ny_true = test_df[class_names].values\ny_pred_probs = model.predict(test_ds.take(test_steps))\ny_pred = (y_pred_probs > 0.5).astype(int)\n\nprint(\"\\nClassification Report:\\n\", classification_report(y_true[:len(y_pred)], y_pred, target_names=class_names))\nprint(\"Macro F1 Score:\", f1_score(y_true[:len(y_pred)], y_pred, average='macro'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T06:22:03.538518Z","iopub.execute_input":"2025-04-25T06:22:03.538835Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1745562124.849962      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1745562124.850636      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1745562153.504987      31 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\nI0000 00:00:1745562178.486604      97 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 786ms/step - binary_accuracy: 0.7748 - loss: 0.1352 - val_binary_accuracy: 0.7905 - val_loss: 0.1287\nEpoch 2/10\n\u001b[1m  1/839\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 113ms/step - binary_accuracy: 0.7714 - loss: 0.1411","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - binary_accuracy: 0.7714 - loss: 0.1411 - val_binary_accuracy: 0.8200 - val_loss: 0.1170\nEpoch 3/10\n\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 472ms/step - binary_accuracy: 0.7820 - loss: 0.1324 - val_binary_accuracy: 0.7903 - val_loss: 0.1313\nEpoch 4/10\n\u001b[1m  1/839\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 96ms/step - binary_accuracy: 0.7905 - loss: 0.1315","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - binary_accuracy: 0.7905 - loss: 0.1315 - val_binary_accuracy: 0.8200 - val_loss: 0.1198\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m124/839\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:36\u001b[0m 387ms/step - binary_accuracy: 0.7831 - loss: 0.1321","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}