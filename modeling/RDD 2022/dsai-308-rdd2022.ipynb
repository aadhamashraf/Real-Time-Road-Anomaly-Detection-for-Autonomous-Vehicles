{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10827165,"sourceType":"datasetVersion","datasetId":6723075},{"sourceId":11458780,"sourceType":"datasetVersion","datasetId":7179903}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import os\n\n# def count_yolo_classes(label_dir):\n#     class_ids = set()\n    \n#     for filename in os.listdir(label_dir):\n#         if filename.endswith(\".txt\"):\n#             filepath = os.path.join(label_dir, filename)\n#             with open(filepath, 'r') as f:\n#                 for line in f:\n#                     parts = line.strip().split()\n#                     if parts:  # avoid empty lines\n#                         class_id = int(parts[0])\n#                         class_ids.add(class_id)\n    \n#     print(f\"Number of unique classes: {len(class_ids)}\")\n#     print(f\"Classes found: {sorted(class_ids)}\")\n\n# directory_path = \"/kaggle/input/rdd-2022/RDD_SPLIT/train/labels\"\n# count_yolo_classes(directory_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T21:25:43.722893Z","iopub.execute_input":"2025-04-24T21:25:43.723111Z","iopub.status.idle":"2025-04-24T21:26:45.814185Z","shell.execute_reply.started":"2025-04-24T21:25:43.723092Z","shell.execute_reply":"2025-04-24T21:26:45.813538Z"}},"outputs":[{"name":"stdout","text":"Number of unique classes: 5\nClasses found: [0, 1, 2, 3, 4]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# import os\n# from collections import Counter\n\n# labels_dir = '/kaggle/input/rdd-2022/RDD_SPLIT/train/labels'\n# all_classes = []\n\n# for label_file in os.listdir(labels_dir):\n#     if not label_file.endswith('.txt'):\n#         continue\n#     with open(os.path.join(labels_dir, label_file), 'r') as f:\n#         for line in f:\n#             class_id = int(line.strip().split()[0])\n#             all_classes.append(class_id)\n\n# print(Counter(all_classes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T21:29:45.971824Z","iopub.execute_input":"2025-04-24T21:29:45.972503Z","iopub.status.idle":"2025-04-24T21:29:57.672922Z","shell.execute_reply.started":"2025-04-24T21:29:45.972477Z","shell.execute_reply":"2025-04-24T21:29:57.672179Z"}},"outputs":[{"name":"stdout","text":"Counter({0: 18201, 1: 8386, 3: 7554, 2: 7527, 4: 4628})\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# import os\n# import shutil\n# import pandas as pd\n\n# # Define class mappings (human-readable damage labels)\n# class_id_to_name = {\n#     0: 'longitudinal_crack',\n#     1: 'transverse_crack',\n#     2: 'alligator_crack',\n#     3: 'pothole',\n#     4: 'other_damage'\n# }\n\n# class_names = list(class_id_to_name.values())\n# num_classes = len(class_names)\n\n# # Dataset paths\n# original_base = '/kaggle/input/rdd-2022/RDD_SPLIT'\n# splits = ['train', 'val', 'test']\n# new_base = '/kaggle/working/'\n\n# # Loop through the splits (train, val, test) to process CSVs\n# for split in splits:\n#     labels_dir = os.path.join(original_base, split, 'labels')\n#     data = []\n\n#     # Process each label file in the 'labels' directory\n#     for label_file in os.listdir(labels_dir):\n#         if not label_file.lower().endswith('.txt'):\n#             continue\n\n#         label_path = os.path.join(labels_dir, label_file)\n#         label_vector = [0] * num_classes\n\n#         with open(label_path, 'r') as f:\n#             for line in f:\n#                 class_id = int(line.strip().split()[0])\n#                 if class_id in class_id_to_name:\n#                     label_vector[class_id] = 1\n\n#         # Assuming you have a naming convention for image files (e.g., the label file name matches the image file name)\n#         img_file = label_file.replace('.txt', '.jpg')  # or .png, .jpeg based on your dataset format\n#         data.append([img_file] + label_vector)\n\n#     # Save the CSV file for the current split\n#     df = pd.DataFrame(data, columns=['filename'] + class_names)\n#     df.to_csv(os.path.join(new_base, f'{split}_labels.csv'), index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T21:32:40.524902Z","iopub.execute_input":"2025-04-24T21:32:40.525361Z","iopub.status.idle":"2025-04-24T21:33:23.703127Z","shell.execute_reply.started":"2025-04-24T21:32:40.525327Z","shell.execute_reply":"2025-04-24T21:33:23.702560Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.losses import BinaryFocalCrossentropy\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, f1_score\n\n# Constants\nnew_base = '/kaggle/input/rdd-2022/RDD_SPLIT'\ncsv_base = '/kaggle/working'\nbatch_size = 32\ntarget_size = (224, 224)\n\n# Class names\nclass_names = ['longitudinal_crack', 'transverse_crack', 'alligator_crack', 'pothole', 'other_damage']\nnum_classes = len(class_names)\n\n# Load data\ntrain_df = pd.read_csv(os.path.join(csv_base, 'train_labels.csv'))\nval_df = pd.read_csv(os.path.join(csv_base, 'val_labels.csv'))\ntest_df = pd.read_csv(os.path.join(csv_base, 'test_labels.csv'))\n\n# Compute class weights from integer labels\ny_train = train_df[class_names].values\ny_train_classes = np.argmax(y_train, axis=1)\nweights = compute_class_weight(class_weight='balanced', classes=np.arange(num_classes), y=y_train_classes)\nclass_weight_dict = {i: weights[i] for i in range(num_classes)}\n\n# Image generator\ndef create_datagen(df, directory, batch_size, target_size, class_names, shuffle=False):\n    def generator():\n        indices = df.index.tolist()\n        if shuffle:\n            np.random.shuffle(indices)\n        for i in indices:\n            row = df.loc[i]\n            img_path = os.path.join(directory, row['filename'])\n            img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n            img_array = tf.keras.preprocessing.image.img_to_array(img)\n            label = row[class_names].values.astype('float32')\n            yield img_array, label\n\n    dataset = tf.data.Dataset.from_generator(\n        generator,\n        output_types=(tf.float32, tf.float32),\n        output_shapes=([*target_size, 3], [len(class_names)])\n    )\n    return dataset.batch(batch_size).repeat().prefetch(tf.data.AUTOTUNE)\n\n# Dataset paths\ntrain_dir = os.path.join(new_base, 'train/images')\nval_dir = os.path.join(new_base, 'val/images')\ntest_dir = os.path.join(new_base, 'test/images')\n\n# Datasets\ntrain_ds = create_datagen(train_df, train_dir, batch_size, target_size, class_names, shuffle=True)\nval_ds = create_datagen(val_df, val_dir, batch_size, target_size, class_names)\ntest_ds = create_datagen(test_df, test_dir, batch_size, target_size, class_names)\n\nsteps_per_epoch = len(train_df) // batch_size\nvalidation_steps = len(val_df) // batch_size\ntest_steps = len(test_df) // batch_size\n\n# Augmentation\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n    layers.RandomContrast(0.1),\n])\n\n# Model builder\ndef build_model(input_shape, num_classes):\n    base_model = EfficientNetB3(include_top=False, input_shape=input_shape, weights='imagenet')\n    base_model.trainable = False\n\n    inputs = layers.Input(shape=input_shape)\n    x = data_augmentation(inputs)\n    x = layers.Rescaling(1./255)(x)\n    x = base_model(x, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.3)(x)\n    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n\n    return models.Model(inputs, outputs)\n\n# Loss and callbacks\nfocal_loss = BinaryFocalCrossentropy(gamma=2.0)\ncheckpoint_cb = callbacks.ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_binary_accuracy', mode='max')\nearly_stop_cb = callbacks.EarlyStopping(patience=6, restore_best_weights=True)\n\n# Compile model\nmodel = build_model((224, 224, 3), num_classes)\nmodel.compile(optimizer='adam', loss=focal_loss, metrics=['binary_accuracy'])\n\n# Train - Phase 1\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=10,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=[checkpoint_cb, early_stop_cb],\n    class_weight=class_weight_dict\n)\n\n# Unfreeze last N layers for fine-tuning\nbase_model = model.get_layer(index=2)\nfor layer in base_model.layers[-30:]:\n    layer.trainable = True\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss=focal_loss, metrics=['binary_accuracy'])\n\n# Train - Phase 2\nfine_tune_history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=10,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=[checkpoint_cb]\n)\n\n# Evaluate\nmodel.load_weights('best_model.keras')\ntest_loss, test_acc = model.evaluate(test_ds.take(test_steps))\nprint(f\"Final Test Accuracy: {test_acc:.4f}, Loss: {test_loss:.4f}\")\n\n# Classification report\ny_true = test_df[class_names].values\ny_pred_probs = model.predict(test_ds.take(test_steps))\ny_pred = (y_pred_probs > 0.5).astype(int)\n\nprint(\"\\nClassification Report:\\n\", classification_report(y_true[:len(y_pred)], y_pred, target_names=class_names))\nprint(\"Macro F1 Score:\", f1_score(y_true[:len(y_pred)], y_pred, average='macro'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T21:50:59.000583Z","iopub.execute_input":"2025-04-24T21:50:59.001214Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1745531460.299903      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1745531460.300542      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1745531488.018729      31 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\nI0000 00:00:1745531491.172566     100 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m630s\u001b[0m 718ms/step - binary_accuracy: 0.7563 - loss: 0.1450 - val_binary_accuracy: 0.7905 - val_loss: 0.1388\nEpoch 2/10\n\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 507ms/step - binary_accuracy: 0.7650 - loss: 0.1444 - val_binary_accuracy: 0.7907 - val_loss: 0.1503\nEpoch 3/10\n\u001b[1m839/839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 493ms/step - binary_accuracy: 0.7678 - loss: 0.1440 - val_binary_accuracy: 0.7910 - val_loss: 0.1427\nEpoch 4/10\n\u001b[1m256/839\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:44\u001b[0m 385ms/step - binary_accuracy: 0.7717 - loss: 0.1431","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}